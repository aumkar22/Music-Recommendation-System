{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GetData and Playlists.ipynb","version":"0.3.2","provenance":[{"file_id":"https://github.com/aumkar22/Music-Recommendation-System/blob/master/GetData.ipynb","timestamp":1543399807322}],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"zqzQTW-1Oxo3","colab_type":"text"},"cell_type":"markdown","source":["# Music-Recommender System\n","##**General outline:**\n","\n","###Hack To Get Data\n","*   Before using, adjust this file to your file hierachy under **Hack to get Data/Local storage**\n","*   The msd subset is stored as hfd5 files, **HDF5 Getters (imported) and necessary function** contains all functions to process those\n","*   Two individual datasets are created\n","\n","> * one non-audio set (containing features like artist etc.)\n",">> * **Extract non audio**\n","> * one audio set (containing musical features)\n",">> * **Extract audio**\n","* Since already the subset takes some time to be processed. 'smallset' is a subset of the subset containing 53 files. Whenever the hfd5 files are extracted, use *smallset* instead of *msd_subset_data_path* to extract if you want quick results\n","* Pandas Dataframe for non Audio: *nonAudioData*\n","* Pandas Dataframe for  Audio: *audioData*\n","\n","\n","\n","\n"]},{"metadata":{"id":"fu04RYkEjofw","colab_type":"code","outputId":"f0df386f-44db-4129-ccc6-3a86b35813c0","executionInfo":{"status":"ok","timestamp":1544350051834,"user_tz":-60,"elapsed":5140,"user":{"displayName":"Sonja Füllhase","photoUrl":"","userId":"11794806925355905588"}},"colab":{"base_uri":"https://localhost:8080/","height":207}},"cell_type":"code","source":["!pip install tables"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting tables\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/1b/21f4c7f296b718575c17ef25e61c05742a283c45077b4c8d5a190b3e0b59/tables-3.4.4-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n","\u001b[K    100% |████████████████████████████████| 3.8MB 6.4MB/s \n","\u001b[?25hCollecting numexpr>=2.5.2 (from tables)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/ea/efd9e16283637eb5b6c0042b6cc3521f1b9a5b47767ac463c88bbd37670c/numexpr-2.6.8-cp36-cp36m-manylinux1_x86_64.whl (162kB)\n","\u001b[K    100% |████████████████████████████████| 163kB 14.4MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from tables) (1.14.6)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from tables) (1.11.0)\n","Installing collected packages: numexpr, tables\n","Successfully installed numexpr-2.6.8 tables-3.4.4\n"],"name":"stdout"}]},{"metadata":{"id":"hMloGVsLjh4j","colab_type":"text"},"cell_type":"markdown","source":["##Hack to get the data "]},{"metadata":{"id":"I7l1qgDfjhLI","colab_type":"code","colab":{}},"cell_type":"code","source":["import os\n","import sys\n","import time\n","import glob\n","import datetime\n","import sqlite3\n","import numpy as np\n","import tarfile\n","import tables\n","import numpy as np\n","import random\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from google.colab import drive"],"execution_count":0,"outputs":[]},{"metadata":{"id":"U8wePVe5j7Si","colab_type":"text"},"cell_type":"markdown","source":["**Local Storage**"]},{"metadata":{"id":"XCZwZ-8Oj4gC","colab_type":"code","outputId":"5eb89f67-8a44-497b-91a8-c69c4f43c446","executionInfo":{"status":"ok","timestamp":1544350077961,"user_tz":-60,"elapsed":24826,"user":{"displayName":"Sonja Füllhase","photoUrl":"","userId":"11794806925355905588"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"cell_type":"code","source":["drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"metadata":{"id":"0H7Q_OM6kYsa","colab_type":"code","outputId":"5f7d5996-1de7-4a1a-b44e-b931766d0cae","executionInfo":{"status":"ok","timestamp":1544350079753,"user_tz":-60,"elapsed":801,"user":{"displayName":"Sonja Füllhase","photoUrl":"","userId":"11794806925355905588"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"cell_type":"code","source":["msd_subset_path=r'/content/drive/My Drive/IR/Dataprocessing/MillionSongSubset'\n","msd_subset_data_path=os.path.join(msd_subset_path,'data')\n","msd_subset_addf_path=os.path.join(msd_subset_path,'AdditionalFiles')\n","smallset = r'/content/drive/My Drive/IR/Dataprocessing/A'\n","msd_code_path=r'/content/drive/My Drive/IR/Dataprocessing'\n","sys.path.append( os.path.join(msd_code_path,'PythonSrc') )\n","sys.path.append( os.path.join(msd_code_path,'PythonSrc') )\n","\n","#Is the given path really a path?\n","print(os.path.isdir(msd_subset_path))\n","print(os.path.exists(msd_subset_path))\n","print(os.path.isdir(msd_code_path))\n","print(os.path.exists(msd_code_path))\n","print(os.path.isdir(smallset))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["True\n","True\n","True\n","True\n","True\n"],"name":"stdout"}]},{"metadata":{"id":"H491UsVtjyR6","colab_type":"text"},"cell_type":"markdown","source":["###HDF5 Getters (imported) and necessary function"]},{"metadata":{"id":"YWh0KsSojgPD","colab_type":"code","colab":{}},"cell_type":"code","source":["\"\"\"\n","Thierry Bertin-Mahieux (2010) Columbia University\n","tb2332@columbia.edu\n","This code contains a set of getters functions to access the fields\n","from an HDF5 song file (regular file with one song or\n","aggregate / summary file with many songs)\n","This is part of the Million Song Dataset project from\n","LabROSA (Columbia University) and The Echo Nest.\n","Copyright 2010, Thierry Bertin-Mahieux\n","This program is free software: you can redistribute it and/or modify\n","it under the terms of the GNU General Public License as published by\n","the Free Software Foundation, either version 3 of the License, or\n","(at your option) any later version.\n","This program is distributed in the hope that it will be useful,\n","but WITHOUT ANY WARRANTY; without even the implied warranty of\n","MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n","GNU General Public License for more details.\n","You should have received a copy of the GNU General Public License\n","along with this program.  If not, see <http://www.gnu.org/licenses/>.\n","\"\"\"\n","\n","\n","def open_h5_file_read(h5filename):\n","    \"\"\"\n","    Open an existing H5 in read mode.\n","    Same function as in hdf5_utils, here so we avoid one import\n","    \"\"\"\n","    return tables.open_file(h5filename, mode='r')\n","\n","\n","def get_num_songs(h5):\n","    \"\"\"\n","    Return the number of songs contained in this h5 file, i.e. the number of rows\n","    for all basic informations like name, artist, ...\n","    \"\"\"\n","    return h5.root.metadata.songs.nrows\n","\n","def get_artist_familiarity(h5,songidx=0):\n","    \"\"\"\n","    Get artist familiarity from a HDF5 song file, by default the first song in it\n","    \"\"\"\n","    return h5.root.metadata.songs.cols.artist_familiarity[songidx]\n","\n","def get_artist_hotttnesss(h5,songidx=0):\n","    \"\"\"\n","    Get artist hotttnesss from a HDF5 song file, by default the first song in it\n","    \"\"\"\n","    return h5.root.metadata.songs.cols.artist_hotttnesss[songidx]\n","\n","def get_artist_id(h5,songidx=0):\n","    \"\"\"\n","    Get artist id from a HDF5 song file, by default the first song in it\n","    \"\"\"\n","    return h5.root.metadata.songs.cols.artist_id[songidx]\n","\n","def get_artist_mbid(h5,songidx=0):\n","    \"\"\"\n","    Get artist musibrainz id from a HDF5 song file, by default the first song in it\n","    \"\"\"\n","    return h5.root.metadata.songs.cols.artist_mbid[songidx]\n","\n","def get_artist_playmeid(h5,songidx=0):\n","    \"\"\"\n","    Get artist playme id from a HDF5 song file, by default the first song in it\n","    \"\"\"\n","    return h5.root.metadata.songs.cols.artist_playmeid[songidx]\n","\n","def get_artist_7digitalid(h5,songidx=0):\n","    \"\"\"\n","    Get artist 7digital id from a HDF5 song file, by default the first song in it\n","    \"\"\"\n","    return h5.root.metadata.songs.cols.artist_7digitalid[songidx]\n","\n","def get_artist_latitude(h5,songidx=0):\n","    \"\"\"\n","    Get artist latitude from a HDF5 song file, by default the first song in it\n","    \"\"\"\n","    return h5.root.metadata.songs.cols.artist_latitude[songidx]\n","\n","def get_artist_longitude(h5,songidx=0):\n","    \"\"\"\n","    Get artist longitude from a HDF5 song file, by default the first song in it\n","    \"\"\"\n","    return h5.root.metadata.songs.cols.artist_longitude[songidx]\n","\n","def get_artist_location(h5,songidx=0):\n","    \"\"\"\n","    Get artist location from a HDF5 song file, by default the first song in it\n","    \"\"\"\n","    return h5.root.metadata.songs.cols.artist_location[songidx]\n","\n","def get_artist_name(h5,songidx=0):\n","    \"\"\"\n","    Get artist name from a HDF5 song file, by default the first song in it\n","    \"\"\"\n","    return h5.root.metadata.songs.cols.artist_name[songidx]\n","\n","def get_release(h5,songidx=0):\n","    \"\"\"\n","    Get release from a HDF5 song file, by default the first song in it\n","    \"\"\"\n","    return h5.root.metadata.songs.cols.release[songidx]\n","\n","def get_release_7digitalid(h5,songidx=0):\n","    \"\"\"\n","    Get release 7digital id from a HDF5 song file, by default the first song in it\n","    \"\"\"\n","    return h5.root.metadata.songs.cols.release_7digitalid[songidx]\n","\n","def get_song_id(h5,songidx=0):\n","    \"\"\"\n","    Get song id from a HDF5 song file, by default the first song in it\n","    \"\"\"\n","    return h5.root.metadata.songs.cols.song_id[songidx]\n","\n","def get_song_hotttnesss(h5,songidx=0):\n","    \"\"\"\n","    Get song hotttnesss from a HDF5 song file, by default the first song in it\n","    \"\"\"\n","    return h5.root.metadata.songs.cols.song_hotttnesss[songidx]\n","\n","def get_title(h5,songidx=0):\n","    \"\"\"\n","    Get title from a HDF5 song file, by default the first song in it\n","    \"\"\"\n","    return h5.root.metadata.songs.cols.title[songidx]\n","\n","def get_track_7digitalid(h5,songidx=0):\n","    \"\"\"\n","    Get track 7digital id from a HDF5 song file, by default the first song in it\n","    \"\"\"\n","    return h5.root.metadata.songs.cols.track_7digitalid[songidx]\n","\n","def get_similar_artists(h5,songidx=0):\n","    \"\"\"\n","    Get similar artists array. Takes care of the proper indexing if we are in aggregate\n","    file. By default, return the array for the first song in the h5 file.\n","    To get a regular numpy ndarray, cast the result to: numpy.array( )\n","    \"\"\"\n","    if h5.root.metadata.songs.nrows == songidx + 1:\n","        return h5.root.metadata.similar_artists[h5.root.metadata.songs.cols.idx_similar_artists[songidx]:]\n","    return h5.root.metadata.similar_artists[h5.root.metadata.songs.cols.idx_similar_artists[songidx]:\n","                                            h5.root.metadata.songs.cols.idx_similar_artists[songidx+1]]\n","\n","def get_artist_terms(h5,songidx=0):\n","    \"\"\"\n","    Get artist terms array. Takes care of the proper indexing if we are in aggregate\n","    file. By default, return the array for the first song in the h5 file.\n","    To get a regular numpy ndarray, cast the result to: numpy.array( )\n","    \"\"\"\n","    if h5.root.metadata.songs.nrows == songidx + 1:\n","        return h5.root.metadata.artist_terms[h5.root.metadata.songs.cols.idx_artist_terms[songidx]:]\n","    return h5.root.metadata.artist_terms[h5.root.metadata.songs.cols.idx_artist_terms[songidx]:\n","                                            h5.root.metadata.songs.cols.idx_artist_terms[songidx+1]]\n","\n","def get_artist_terms_freq(h5,songidx=0):\n","    \"\"\"\n","    Get artist terms array frequencies. Takes care of the proper indexing if we are in aggregate\n","    file. By default, return the array for the first song in the h5 file.\n","    To get a regular numpy ndarray, cast the result to: numpy.array( )\n","    \"\"\"\n","    if h5.root.metadata.songs.nrows == songidx + 1:\n","        return h5.root.metadata.artist_terms_freq[h5.root.metadata.songs.cols.idx_artist_terms[songidx]:]\n","    return h5.root.metadata.artist_terms_freq[h5.root.metadata.songs.cols.idx_artist_terms[songidx]:\n","                                              h5.root.metadata.songs.cols.idx_artist_terms[songidx+1]]\n","\n","def get_artist_terms_weight(h5,songidx=0):\n","    \"\"\"\n","    Get artist terms array frequencies. Takes care of the proper indexing if we are in aggregate\n","    file. By default, return the array for the first song in the h5 file.\n","    To get a regular numpy ndarray, cast the result to: numpy.array( )\n","    \"\"\"\n","    if h5.root.metadata.songs.nrows == songidx + 1:\n","        return h5.root.metadata.artist_terms_weight[h5.root.metadata.songs.cols.idx_artist_terms[songidx]:]\n","    return h5.root.metadata.artist_terms_weight[h5.root.metadata.songs.cols.idx_artist_terms[songidx]:\n","                                                h5.root.metadata.songs.cols.idx_artist_terms[songidx+1]]\n","\n","def get_analysis_sample_rate(h5,songidx=0):\n","    \"\"\"\n","    Get analysis sample rate from a HDF5 song file, by default the first song in it\n","    \"\"\"\n","    return h5.root.analysis.songs.cols.analysis_sample_rate[songidx]\n","\n","def get_audio_md5(h5,songidx=0):\n","    \"\"\"\n","    Get audio MD5 from a HDF5 song file, by default the first song in it\n","    \"\"\"\n","    return h5.root.analysis.songs.cols.audio_md5[songidx]\n","\n","def get_danceability(h5,songidx=0):\n","    \"\"\"\n","    Get danceability from a HDF5 song file, by default the first song in it\n","    \"\"\"\n","    return h5.root.analysis.songs.cols.danceability[songidx]\n","\n","def get_duration(h5,songidx=0):\n","    \"\"\"\n","    Get duration from a HDF5 song file, by default the first song in it\n","    \"\"\"\n","    return h5.root.analysis.songs.cols.duration[songidx]\n","\n","def get_end_of_fade_in(h5,songidx=0):\n","    \"\"\"\n","    Get end of fade in from a HDF5 song file, by default the first song in it\n","    \"\"\"\n","    return h5.root.analysis.songs.cols.end_of_fade_in[songidx]\n","\n","def get_energy(h5,songidx=0):\n","    \"\"\"\n","    Get energy from a HDF5 song file, by default the first song in it\n","    \"\"\"\n","    return h5.root.analysis.songs.cols.energy[songidx]\n","\n","def get_key(h5,songidx=0):\n","    \"\"\"\n","    Get key from a HDF5 song file, by default the first song in it\n","    \"\"\"\n","    return h5.root.analysis.songs.cols.key[songidx]\n","\n","def get_key_confidence(h5,songidx=0):\n","    \"\"\"\n","    Get key confidence from a HDF5 song file, by default the first song in it\n","    \"\"\"\n","    return h5.root.analysis.songs.cols.key_confidence[songidx]\n","\n","def get_loudness(h5,songidx=0):\n","    \"\"\"\n","    Get loudness from a HDF5 song file, by default the first song in it\n","    \"\"\"\n","    return h5.root.analysis.songs.cols.loudness[songidx]\n","\n","def get_mode(h5,songidx=0):\n","    \"\"\"\n","    Get mode from a HDF5 song file, by default the first song in it\n","    \"\"\"\n","    return h5.root.analysis.songs.cols.mode[songidx]\n","\n","def get_mode_confidence(h5,songidx=0):\n","    \"\"\"\n","    Get mode confidence from a HDF5 song file, by default the first song in it\n","    \"\"\"\n","    return h5.root.analysis.songs.cols.mode_confidence[songidx]\n","\n","def get_start_of_fade_out(h5,songidx=0):\n","    \"\"\"\n","    Get start of fade out from a HDF5 song file, by default the first song in it\n","    \"\"\"\n","    return h5.root.analysis.songs.cols.start_of_fade_out[songidx]\n","\n","def get_tempo(h5,songidx=0):\n","    \"\"\"\n","    Get tempo from a HDF5 song file, by default the first song in it\n","    \"\"\"\n","    return h5.root.analysis.songs.cols.tempo[songidx]\n","\n","def get_time_signature(h5,songidx=0):\n","    \"\"\"\n","    Get signature from a HDF5 song file, by default the first song in it\n","    \"\"\"\n","    return h5.root.analysis.songs.cols.time_signature[songidx]\n","\n","def get_time_signature_confidence(h5,songidx=0):\n","    \"\"\"\n","    Get signature confidence from a HDF5 song file, by default the first song in it\n","    \"\"\"\n","    return h5.root.analysis.songs.cols.time_signature_confidence[songidx]\n","\n","def get_track_id(h5,songidx=0):\n","    \"\"\"\n","    Get track id from a HDF5 song file, by default the first song in it\n","    \"\"\"\n","    return h5.root.analysis.songs.cols.track_id[songidx]\n","\n","def get_segments_start(h5,songidx=0):\n","    \"\"\"\n","    Get segments start array. Takes care of the proper indexing if we are in aggregate\n","    file. By default, return the array for the first song in the h5 file.\n","    To get a regular numpy ndarray, cast the result to: numpy.array( )\n","    \"\"\"\n","    h5 = os.path.normpath(h5)\n","    if h5.root.analysis.songs.nrows == songidx + 1:\n","        return h5.root.analysis.segments_start[h5.root.analysis.songs.cols.idx_segments_start[songidx]:]\n","    return h5.root.analysis.segments_start[h5.root.analysis.songs.cols.idx_segments_start[songidx]:\n","                                           h5.root.analysis.songs.cols.idx_segments_start[songidx+1]]\n","    \n","def get_segments_confidence(h5,songidx=0):\n","    \"\"\"\n","    Get segments confidence array. Takes care of the proper indexing if we are in aggregate\n","    file. By default, return the array for the first song in the h5 file.\n","    To get a regular numpy ndarray, cast the result to: numpy.array( )\n","    \"\"\"\n","    if h5.root.analysis.songs.nrows == songidx + 1:\n","        return h5.root.analysis.segments_confidence[h5.root.analysis.songs.cols.idx_segments_confidence[songidx]:]\n","    return h5.root.analysis.segments_confidence[h5.root.analysis.songs.cols.idx_segments_confidence[songidx]:\n","                                                h5.root.analysis.songs.cols.idx_segments_confidence[songidx+1]]\n","\n","def get_segments_pitches(h5,songidx=0):\n","    \"\"\"\n","    Get segments pitches array. Takes care of the proper indexing if we are in aggregate\n","    file. By default, return the array for the first song in the h5 file.\n","    To get a regular numpy ndarray, cast the result to: numpy.array( )\n","    \"\"\"\n","    if h5.root.analysis.songs.nrows == songidx + 1:\n","        return h5.root.analysis.segments_pitches[h5.root.analysis.songs.cols.idx_segments_pitches[songidx]:,:]\n","    return h5.root.analysis.segments_pitches[h5.root.analysis.songs.cols.idx_segments_pitches[songidx]:\n","                                             h5.root.analysis.songs.cols.idx_segments_pitches[songidx+1],:]\n","\n","def get_segments_timbre(h5,songidx=0):\n","    \"\"\"\n","    Get segments timbre array. Takes care of the proper indexing if we are in aggregate\n","    file. By default, return the array for the first song in the h5 file.\n","    To get a regular numpy ndarray, cast the result to: numpy.array( )\n","    \"\"\"\n","    if h5.root.analysis.songs.nrows == songidx + 1:\n","        return h5.root.analysis.segments_timbre[h5.root.analysis.songs.cols.idx_segments_timbre[songidx]:,:]\n","    return h5.root.analysis.segments_timbre[h5.root.analysis.songs.cols.idx_segments_timbre[songidx]:\n","                                            h5.root.analysis.songs.cols.idx_segments_timbre[songidx+1],:]\n","\n","def get_segments_loudness_max(h5,songidx=0):\n","    \"\"\"\n","    Get segments loudness max array. Takes care of the proper indexing if we are in aggregate\n","    file. By default, return the array for the first song in the h5 file.\n","    To get a regular numpy ndarray, cast the result to: numpy.array( )\n","    \"\"\"\n","    if h5.root.analysis.songs.nrows == songidx + 1:\n","        return h5.root.analysis.segments_loudness_max[h5.root.analysis.songs.cols.idx_segments_loudness_max[songidx]:]\n","    return h5.root.analysis.segments_loudness_max[h5.root.analysis.songs.cols.idx_segments_loudness_max[songidx]:\n","                                                  h5.root.analysis.songs.cols.idx_segments_loudness_max[songidx+1]]\n","\n","def get_segments_loudness_max_time(h5,songidx=0):\n","    \"\"\"\n","    Get segments loudness max time array. Takes care of the proper indexing if we are in aggregate\n","    file. By default, return the array for the first song in the h5 file.\n","    To get a regular numpy ndarray, cast the result to: numpy.array( )\n","    \"\"\"\n","    if h5.root.analysis.songs.nrows == songidx + 1:\n","        return h5.root.analysis.segments_loudness_max_time[h5.root.analysis.songs.cols.idx_segments_loudness_max_time[songidx]:]\n","    return h5.root.analysis.segments_loudness_max_time[h5.root.analysis.songs.cols.idx_segments_loudness_max_time[songidx]:\n","                                                       h5.root.analysis.songs.cols.idx_segments_loudness_max_time[songidx+1]]\n","\n","def get_segments_loudness_start(h5,songidx=0):\n","    \"\"\"\n","    Get segments loudness start array. Takes care of the proper indexing if we are in aggregate\n","    file. By default, return the array for the first song in the h5 file.\n","    To get a regular numpy ndarray, cast the result to: numpy.array( )\n","    \"\"\"\n","    if h5.root.analysis.songs.nrows == songidx + 1:\n","        return h5.root.analysis.segments_loudness_start[h5.root.analysis.songs.cols.idx_segments_loudness_start[songidx]:]\n","    return h5.root.analysis.segments_loudness_start[h5.root.analysis.songs.cols.idx_segments_loudness_start[songidx]:\n","                                                    h5.root.analysis.songs.cols.idx_segments_loudness_start[songidx+1]]\n","\n","def get_sections_start(h5,songidx=0):\n","    \"\"\"\n","    Get sections start array. Takes care of the proper indexing if we are in aggregate\n","    file. By default, return the array for the first song in the h5 file.\n","    To get a regular numpy ndarray, cast the result to: numpy.array( )\n","    \"\"\"\n","    if h5.root.analysis.songs.nrows == songidx + 1:\n","        return h5.root.analysis.sections_start[h5.root.analysis.songs.cols.idx_sections_start[songidx]:]\n","    return h5.root.analysis.sections_start[h5.root.analysis.songs.cols.idx_sections_start[songidx]:\n","                                           h5.root.analysis.songs.cols.idx_sections_start[songidx+1]]\n","\n","def get_sections_confidence(h5,songidx=0):\n","    \"\"\"\n","    Get sections confidence array. Takes care of the proper indexing if we are in aggregate\n","    file. By default, return the array for the first song in the h5 file.\n","    To get a regular numpy ndarray, cast the result to: numpy.array( )\n","    \"\"\"\n","    if h5.root.analysis.songs.nrows == songidx + 1:\n","        return h5.root.analysis.sections_confidence[h5.root.analysis.songs.cols.idx_sections_confidence[songidx]:]\n","    return h5.root.analysis.sections_confidence[h5.root.analysis.songs.cols.idx_sections_confidence[songidx]:\n","                                                h5.root.analysis.songs.cols.idx_sections_confidence[songidx+1]]\n","\n","def get_beats_start(h5,songidx=0):\n","    \"\"\"\n","    Get beats start array. Takes care of the proper indexing if we are in aggregate\n","    file. By default, return the array for the first song in the h5 file.\n","    To get a regular numpy ndarray, cast the result to: numpy.array( )\n","    \"\"\"\n","    if h5.root.analysis.songs.nrows == songidx + 1:\n","        return h5.root.analysis.beats_start[h5.root.analysis.songs.cols.idx_beats_start[songidx]:]\n","    return h5.root.analysis.beats_start[h5.root.analysis.songs.cols.idx_beats_start[songidx]:\n","                                        h5.root.analysis.songs.cols.idx_beats_start[songidx+1]]\n","\n","def get_beats_confidence(h5,songidx=0):\n","    \"\"\"\n","    Get beats confidence array. Takes care of the proper indexing if we are in aggregate\n","    file. By default, return the array for the first song in the h5 file.\n","    To get a regular numpy ndarray, cast the result to: numpy.array( )\n","    \"\"\"\n","    if h5.root.analysis.songs.nrows == songidx + 1:\n","        return h5.root.analysis.beats_confidence[h5.root.analysis.songs.cols.idx_beats_confidence[songidx]:]\n","    return h5.root.analysis.beats_confidence[h5.root.analysis.songs.cols.idx_beats_confidence[songidx]:\n","                                             h5.root.analysis.songs.cols.idx_beats_confidence[songidx+1]]\n","\n","def get_bars_start(h5,songidx=0):\n","    \"\"\"\n","    Get bars start array. Takes care of the proper indexing if we are in aggregate\n","    file. By default, return the array for the first song in the h5 file.\n","    To get a regular numpy ndarray, cast the result to: numpy.array( )\n","    \"\"\"\n","    if h5.root.analysis.songs.nrows == songidx + 1:\n","        return h5.root.analysis.bars_start[h5.root.analysis.songs.cols.idx_bars_start[songidx]:]\n","    return h5.root.analysis.bars_start[h5.root.analysis.songs.cols.idx_bars_start[songidx]:\n","                                       h5.root.analysis.songs.cols.idx_bars_start[songidx+1]]\n","\n","def get_bars_confidence(h5,songidx=0):\n","    \"\"\"\n","    Get bars start array. Takes care of the proper indexing if we are in aggregate\n","    file. By default, return the array for the first song in the h5 file.\n","    To get a regular numpy ndarray, cast the result to: numpy.array( )\n","    \"\"\"\n","    if h5.root.analysis.songs.nrows == songidx + 1:\n","        return h5.root.analysis.bars_confidence[h5.root.analysis.songs.cols.idx_bars_confidence[songidx]:]\n","    return h5.root.analysis.bars_confidence[h5.root.analysis.songs.cols.idx_bars_confidence[songidx]:\n","                                            h5.root.analysis.songs.cols.idx_bars_confidence[songidx+1]]\n","\n","def get_tatums_start(h5,songidx=0):\n","    \"\"\"\n","    Get tatums start array. Takes care of the proper indexing if we are in aggregate\n","    file. By default, return the array for the first song in the h5 file.\n","    To get a regular numpy ndarray, cast the result to: numpy.array( )\n","    \"\"\"\n","    if h5.root.analysis.songs.nrows == songidx + 1:\n","        return h5.root.analysis.tatums_start[h5.root.analysis.songs.cols.idx_tatums_start[songidx]:]\n","    return h5.root.analysis.tatums_start[h5.root.analysis.songs.cols.idx_tatums_start[songidx]:\n","                                         h5.root.analysis.songs.cols.idx_tatums_start[songidx+1]]\n","\n","def get_tatums_confidence(h5,songidx=0):\n","    \"\"\"\n","    Get tatums confidence array. Takes care of the proper indexing if we are in aggregate\n","    file. By default, return the array for the first song in the h5 file.\n","    To get a regular numpy ndarray, cast the result to: numpy.array( )\n","    \"\"\"\n","    if h5.root.analysis.songs.nrows == songidx + 1:\n","        return h5.root.analysis.tatums_confidence[h5.root.analysis.songs.cols.idx_tatums_confidence[songidx]:]\n","    return h5.root.analysis.tatums_confidence[h5.root.analysis.songs.cols.idx_tatums_confidence[songidx]:\n","                                              h5.root.analysis.songs.cols.idx_tatums_confidence[songidx+1]]\n","\n","def get_artist_mbtags(h5,songidx=0):\n","    \"\"\"\n","    Get artist musicbrainz tag array. Takes care of the proper indexing if we are in aggregate\n","    file. By default, return the array for the first song in the h5 file.\n","    To get a regular numpy ndarray, cast the result to: numpy.array( )\n","    \"\"\"\n","    if h5.root.musicbrainz.songs.nrows == songidx + 1:\n","        return h5.root.musicbrainz.artist_mbtags[h5.root.musicbrainz.songs.cols.idx_artist_mbtags[songidx]:]\n","    return h5.root.musicbrainz.artist_mbtags[h5.root.metadata.songs.cols.idx_artist_mbtags[songidx]:\n","                                             h5.root.metadata.songs.cols.idx_artist_mbtags[songidx+1]]\n","\n","def get_artist_mbtags_count(h5,songidx=0):\n","    \"\"\"\n","    Get artist musicbrainz tag count array. Takes care of the proper indexing if we are in aggregate\n","    file. By default, return the array for the first song in the h5 file.\n","    To get a regular numpy ndarray, cast the result to: numpy.array( )\n","    \"\"\"\n","    if h5.root.musicbrainz.songs.nrows == songidx + 1:\n","        return h5.root.musicbrainz.artist_mbtags_count[h5.root.musicbrainz.songs.cols.idx_artist_mbtags[songidx]:]\n","    return h5.root.musicbrainz.artist_mbtags_count[h5.root.metadata.songs.cols.idx_artist_mbtags[songidx]:\n","                                                   h5.root.metadata.songs.cols.idx_artist_mbtags[songidx+1]]\n","\n","def get_year(h5,songidx=0):\n","    \"\"\"\n","    Get release year from a HDF5 song file, by default the first song in it\n","    \"\"\"\n","    return h5.root.musicbrainz.songs.cols.year[songidx]\n"," \n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mT8lSCgUklPt","colab_type":"code","colab":{}},"cell_type":"code","source":["def apply_to_all_files(basedir,func=lambda x: x,ext='.h5'):\n","    \"\"\"\n","    From a base directory, go through all subdirectories,\n","    find all files with the given extension, apply the\n","    given function 'func' to all of them.\n","    If no 'func' is passed, we do nothing except counting.\n","    INPUT\n","       basedir  - base directory of the dataset\n","       func     - function to apply to all filenames\n","       ext      - extension, .h5 by default\n","    RETURN\n","       number of files\n","    \"\"\"\n","    cnt = 0\n","    # iterate over all files in all subdirectories\n","    for root, dirs, files in os.walk(basedir):\n","        files = glob.glob(os.path.join(root,'*'+ext))\n","        # count files\n","        cnt += len(files)\n","        # apply function to all files\n","        for f in files :\n","            func(f)       \n","    return cnt"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jSV7nIXGkopk","colab_type":"code","colab":{}},"cell_type":"code","source":["def strtimedelta(starttime,stoptime):\n","    return str(datetime.timedelta(seconds=stoptime-starttime))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"aFVfqUDRwE7q","colab_type":"text"},"cell_type":"markdown","source":["### Extract non Audio"]},{"metadata":{"id":"UFFSUcD6KKnP","colab_type":"code","colab":{}},"cell_type":"code","source":["all_song_id = []\n","all_artist_id=[]\n","all_artist_name=[]\n","all_release=[]\n","all_title=[]\n","all_danceability=[]\n","all_track_id=[]\n","all_year=[]\n","all_similar_artists=[]\n","all_artist_terms=[]\n","all_artist_terms_freq=[]\n","all_artist_terms_weight =[]\n","\n","def nonAudio(filename):\n","    h5 = open_h5_file_read(filename)\n","    tmp = get_song_id(h5)\n","    all_song_id.append(tmp)\n","    tmp = get_artist_id(h5)\n","    all_artist_id.append(tmp)\n","    tmp = get_artist_name(h5)\n","    all_artist_name.append(tmp)\n","    tmp = get_release(h5)\n","    all_release.append(tmp)\n","    tmp = get_title(h5)\n","    all_title.append(tmp)\n","    tmp = get_danceability(h5)\n","    all_danceability.append(tmp)\n","    tmp = get_track_id(h5)\n","    all_track_id.append(tmp)\n","    tmp = get_year(h5)\n","    all_year.append(tmp)\n","    tmp = get_similar_artists(h5)\n","    all_similar_artists.append(tmp)\n","    tmp = get_artist_terms(h5)\n","    all_artist_terms.append(tmp)\n","    tmp = get_artist_terms_freq(h5)\n","    all_artist_terms_freq.append(tmp)\n","    tmp = get_artist_terms_weight(h5)\n","    all_artist_terms_weight.append(tmp)\n","    h5.close()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-hJMaoRzN_sA","colab_type":"code","outputId":"77cfb2b0-b890-454a-f06f-c3e1fc556d78","executionInfo":{"status":"ok","timestamp":1544350086389,"user_tz":-60,"elapsed":290,"user":{"displayName":"Sonja Füllhase","photoUrl":"","userId":"11794806925355905588"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["count1 = 0\n","count2 = 0\n","for i in all_danceability:\n","    if i == 0:\n","        count1+=1\n","    else:\n","        count2+=1\n","    \n","print(count1,count2)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["0 0\n"],"name":"stdout"}]},{"metadata":{"id":"C-XPxYqrNtCv","colab_type":"text"},"cell_type":"markdown","source":["Change *smallset* to* msd_subset_data_path* to apply function to whole subset $\\rightarrow$ will take ages"]},{"metadata":{"id":"89JtQ1IcLlpl","colab_type":"code","outputId":"6b4c39bb-f00c-4a7b-c5b7-74d61a1783e3","executionInfo":{"status":"ok","timestamp":1544352014988,"user_tz":-60,"elapsed":1860505,"user":{"displayName":"Sonja Füllhase","photoUrl":"","userId":"11794806925355905588"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["t1 = time.time()\n","apply_to_all_files(msd_subset_data_path,func=nonAudio)\n","t2 = time.time()\n","print(t2-t1)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["1860.1833395957947\n"],"name":"stdout"}]},{"metadata":{"id":"15WfejhJ_nNh","colab_type":"code","colab":{}},"cell_type":"code","source":["nonAudio = [all_artist_id,\n","all_artist_name,\n","all_release,\n","all_title,\n","all_danceability,\n","all_track_id,\n","all_year,\n","all_similar_artists,\n","all_artist_terms,\n","all_artist_terms_freq,\n","all_artist_terms_weight]\n","\n","nonAudioLabels = ['artist_id',\n","'artist_name',\n","'release',\n","'title',\n","'danceability',\n","'track_id',\n","'year',\n","'similar_artists',\n","'artist_terms',\n","'artist_terms_freq',\n","'artist_terms_weight']\n","\n","dataNonAudio = pd.DataFrame(nonAudio,index = nonAudioLabels, columns = all_song_id)\n","nonAudioData = dataNonAudio.transpose()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"p0La72QKMhzI","colab_type":"code","outputId":"15f4a67f-79f5-4362-e4a2-89afcb5b5e4b","executionInfo":{"status":"ok","timestamp":1544352015648,"user_tz":-60,"elapsed":1856542,"user":{"displayName":"Sonja Füllhase","photoUrl":"","userId":"11794806925355905588"}},"colab":{"base_uri":"https://localhost:8080/","height":479}},"cell_type":"code","source":["nonAudioData.head()"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>artist_id</th>\n","      <th>artist_name</th>\n","      <th>release</th>\n","      <th>title</th>\n","      <th>danceability</th>\n","      <th>track_id</th>\n","      <th>year</th>\n","      <th>similar_artists</th>\n","      <th>artist_terms</th>\n","      <th>artist_terms_freq</th>\n","      <th>artist_terms_weight</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>b'SOCIWDW12A8C13D406'</th>\n","      <td>b'ARMJAGH1187FB546F3'</td>\n","      <td>b'The Box Tops'</td>\n","      <td>b'Dimensions'</td>\n","      <td>b'Soul Deep'</td>\n","      <td>0</td>\n","      <td>b'TRAAABD128F429CF47'</td>\n","      <td>1969</td>\n","      <td>[b'ARSZWK21187B9B26D7', b'ARLDW2Y1187B9B544F',...</td>\n","      <td>[b'blue-eyed soul', b'pop rock', b'blues-rock'...</td>\n","      <td>[1.0, 0.8931999928346939, 0.7860602885494408, ...</td>\n","      <td>[1.0, 0.8459884034332037, 0.8306895698215381, ...</td>\n","    </tr>\n","    <tr>\n","      <th>b'SOMJBYD12A6D4F8557'</th>\n","      <td>b'ARD0S291187B9B7BF5'</td>\n","      <td>b'Rated R'</td>\n","      <td>b'Da Ghetto Psychic'</td>\n","      <td>b'Keepin It Real (Skit)'</td>\n","      <td>0</td>\n","      <td>b'TRAAAMQ128F1460CD3'</td>\n","      <td>0</td>\n","      <td>[b'ARF93II1187B99F981', b'ART6ONC11C8A421DB9',...</td>\n","      <td>[b'breakbeat', b'dirty south rap', b'hip hop',...</td>\n","      <td>[1.0, 0.8386187613378114, 0.9353130749575775, ...</td>\n","      <td>[1.0, 0.9258286857243918, 0.8650794411328923, ...</td>\n","    </tr>\n","    <tr>\n","      <th>b'SONHOTT12A8C13493C'</th>\n","      <td>b'AR7G5I41187FB4CE6C'</td>\n","      <td>b'Adam Ant'</td>\n","      <td>b'Friend Or Foe'</td>\n","      <td>b'Something Girls'</td>\n","      <td>0</td>\n","      <td>b'TRAAAEF128F4273421'</td>\n","      <td>1982</td>\n","      <td>[b'AR4R0741187FB39AF2', b'AR0D7K21187B9AD14E',...</td>\n","      <td>[b'pop rock', b'new wave', b'dance rock', b'ro...</td>\n","      <td>[0.9885838625154639, 0.9672504640243684, 0.820...</td>\n","      <td>[1.0, 0.9636972066614938, 0.9267729972686404, ...</td>\n","    </tr>\n","    <tr>\n","      <th>b'SOXVLOJ12AB0189215'</th>\n","      <td>b'ARKRRTF1187B9984DA'</td>\n","      <td>b'Sonora Santanera'</td>\n","      <td>b'Las Numero 1 De La Sonora Santanera'</td>\n","      <td>b'Amor De Cabaret'</td>\n","      <td>0</td>\n","      <td>b'TRAAADZ128F9348C2E'</td>\n","      <td>0</td>\n","      <td>[b'ARFSJUG11C8A421AAD', b'AR8SD041187FB36015',...</td>\n","      <td>[b'salsa', b'cumbia', b'tejano', b'ranchera', ...</td>\n","      <td>[1.0, 0.9422390717941641, 0.9422390717941641, ...</td>\n","      <td>[1.0, 0.9582578450180738, 0.9582578450180738, ...</td>\n","    </tr>\n","    <tr>\n","      <th>b'SOMZWCG12A8C13C480'</th>\n","      <td>b'ARD7TVE1187B99BFB1'</td>\n","      <td>b'Casual'</td>\n","      <td>b'Fear Itself'</td>\n","      <td>b\"I Didn't Mean To\"</td>\n","      <td>0</td>\n","      <td>b'TRAAAAW128F429D538'</td>\n","      <td>0</td>\n","      <td>[b'ARV4KO21187FB38008', b'ARWHM281187FB3D381',...</td>\n","      <td>[b'hip hop', b'underground rap', b'g funk', b'...</td>\n","      <td>[1.0, 0.7761362332679642, 0.7296697949672141, ...</td>\n","      <td>[1.0, 0.8979359555142553, 0.8842618474718359, ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                   artist_id          artist_name  \\\n","b'SOCIWDW12A8C13D406'  b'ARMJAGH1187FB546F3'      b'The Box Tops'   \n","b'SOMJBYD12A6D4F8557'  b'ARD0S291187B9B7BF5'           b'Rated R'   \n","b'SONHOTT12A8C13493C'  b'AR7G5I41187FB4CE6C'          b'Adam Ant'   \n","b'SOXVLOJ12AB0189215'  b'ARKRRTF1187B9984DA'  b'Sonora Santanera'   \n","b'SOMZWCG12A8C13C480'  b'ARD7TVE1187B99BFB1'            b'Casual'   \n","\n","                                                      release  \\\n","b'SOCIWDW12A8C13D406'                           b'Dimensions'   \n","b'SOMJBYD12A6D4F8557'                    b'Da Ghetto Psychic'   \n","b'SONHOTT12A8C13493C'                        b'Friend Or Foe'   \n","b'SOXVLOJ12AB0189215'  b'Las Numero 1 De La Sonora Santanera'   \n","b'SOMZWCG12A8C13C480'                          b'Fear Itself'   \n","\n","                                          title danceability  \\\n","b'SOCIWDW12A8C13D406'              b'Soul Deep'            0   \n","b'SOMJBYD12A6D4F8557'  b'Keepin It Real (Skit)'            0   \n","b'SONHOTT12A8C13493C'        b'Something Girls'            0   \n","b'SOXVLOJ12AB0189215'        b'Amor De Cabaret'            0   \n","b'SOMZWCG12A8C13C480'       b\"I Didn't Mean To\"            0   \n","\n","                                    track_id  year  \\\n","b'SOCIWDW12A8C13D406'  b'TRAAABD128F429CF47'  1969   \n","b'SOMJBYD12A6D4F8557'  b'TRAAAMQ128F1460CD3'     0   \n","b'SONHOTT12A8C13493C'  b'TRAAAEF128F4273421'  1982   \n","b'SOXVLOJ12AB0189215'  b'TRAAADZ128F9348C2E'     0   \n","b'SOMZWCG12A8C13C480'  b'TRAAAAW128F429D538'     0   \n","\n","                                                         similar_artists  \\\n","b'SOCIWDW12A8C13D406'  [b'ARSZWK21187B9B26D7', b'ARLDW2Y1187B9B544F',...   \n","b'SOMJBYD12A6D4F8557'  [b'ARF93II1187B99F981', b'ART6ONC11C8A421DB9',...   \n","b'SONHOTT12A8C13493C'  [b'AR4R0741187FB39AF2', b'AR0D7K21187B9AD14E',...   \n","b'SOXVLOJ12AB0189215'  [b'ARFSJUG11C8A421AAD', b'AR8SD041187FB36015',...   \n","b'SOMZWCG12A8C13C480'  [b'ARV4KO21187FB38008', b'ARWHM281187FB3D381',...   \n","\n","                                                            artist_terms  \\\n","b'SOCIWDW12A8C13D406'  [b'blue-eyed soul', b'pop rock', b'blues-rock'...   \n","b'SOMJBYD12A6D4F8557'  [b'breakbeat', b'dirty south rap', b'hip hop',...   \n","b'SONHOTT12A8C13493C'  [b'pop rock', b'new wave', b'dance rock', b'ro...   \n","b'SOXVLOJ12AB0189215'  [b'salsa', b'cumbia', b'tejano', b'ranchera', ...   \n","b'SOMZWCG12A8C13C480'  [b'hip hop', b'underground rap', b'g funk', b'...   \n","\n","                                                       artist_terms_freq  \\\n","b'SOCIWDW12A8C13D406'  [1.0, 0.8931999928346939, 0.7860602885494408, ...   \n","b'SOMJBYD12A6D4F8557'  [1.0, 0.8386187613378114, 0.9353130749575775, ...   \n","b'SONHOTT12A8C13493C'  [0.9885838625154639, 0.9672504640243684, 0.820...   \n","b'SOXVLOJ12AB0189215'  [1.0, 0.9422390717941641, 0.9422390717941641, ...   \n","b'SOMZWCG12A8C13C480'  [1.0, 0.7761362332679642, 0.7296697949672141, ...   \n","\n","                                                     artist_terms_weight  \n","b'SOCIWDW12A8C13D406'  [1.0, 0.8459884034332037, 0.8306895698215381, ...  \n","b'SOMJBYD12A6D4F8557'  [1.0, 0.9258286857243918, 0.8650794411328923, ...  \n","b'SONHOTT12A8C13493C'  [1.0, 0.9636972066614938, 0.9267729972686404, ...  \n","b'SOXVLOJ12AB0189215'  [1.0, 0.9582578450180738, 0.9582578450180738, ...  \n","b'SOMZWCG12A8C13C480'  [1.0, 0.8979359555142553, 0.8842618474718359, ...  "]},"metadata":{"tags":[]},"execution_count":12}]},{"metadata":{"id":"nispdxVmkr6V","colab_type":"text"},"cell_type":"markdown","source":["###Extract Audio"]},{"metadata":{"id":"oJbjbUvIkt-P","colab_type":"code","colab":{}},"cell_type":"code","source":["all_analysis_sample_rate = []\n","all_tempo = []\n","all_time_signature = []\n","all_segments_pitches= []\n","all_segments_timbre= []\n","all_segments_loudness_max= []\n","all_song_id = []\n","\n","def extractAudio(filename): \n","  \n","    h5 = open_h5_file_read(filename)\n","    tmp = get_song_id(h5)\n","    all_song_id.append(tmp)\n","    tmp = get_analysis_sample_rate(h5)\n","    all_analysis_sample_rate.append(tmp)\n","    tmp = get_time_signature(h5)\n","    all_time_signature.append(tmp)\n","    tmp = get_tempo(h5)\n","    all_tempo.append(tmp)\n","    tmp = get_segments_pitches(h5)\n","    all_segments_pitches.append(tmp)\n","    tmp = get_segments_timbre(h5) \n","    all_segments_timbre.append(tmp)\n","    tmp = get_segments_loudness_max(h5)\n","    all_segments_loudness_max.append(tmp)\n","    h5.close()    "],"execution_count":0,"outputs":[]},{"metadata":{"id":"qQ9sGBRcnp2j","colab_type":"text"},"cell_type":"markdown","source":["run for a small subset"]},{"metadata":{"id":"3P_VGbFgnDBc","colab_type":"code","outputId":"0b9509de-d20c-410e-9190-44ae161e8876","executionInfo":{"status":"error","timestamp":1544276271286,"user_tz":-60,"elapsed":53095,"user":{"displayName":"Sonja Füllhase","photoUrl":"","userId":"11794806925355905588"}},"colab":{"base_uri":"https://localhost:8080/","height":796}},"cell_type":"code","source":["t1 = time.time()\n","apply_to_all_files(msd_subset_data_path,func=extractAudio)\n","t2 = time.time()"],"execution_count":0,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-a756440dcfbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mapply_to_all_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsd_subset_data_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextractAudio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-cf1035472f7e>\u001b[0m in \u001b[0;36mapply_to_all_files\u001b[0;34m(basedir, func, ext)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# apply function to all files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcnt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-14-6fb9179ff911>\u001b[0m in \u001b[0;36mextractAudio\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextractAudio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mh5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen_h5_file_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_song_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mall_song_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-15b4da18d4af>\u001b[0m in \u001b[0;36mopen_h5_file_read\u001b[0;34m(h5filename)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mSame\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhdf5_utils\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhere\u001b[0m \u001b[0mso\u001b[0m \u001b[0mwe\u001b[0m \u001b[0mavoid\u001b[0m \u001b[0mone\u001b[0m \u001b[0;32mimport\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \"\"\"\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tables/file.py\u001b[0m in \u001b[0;36mopen_file\u001b[0;34m(filename, mode, title, root_uep, filters, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[0;31m# Finally, create the File instance, and return it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_uep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tables/file.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, title, root_uep, filters, **kwargs)\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m         \u001b[0;31m# Now, it is time to initialize the File extension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_g_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[0;31m# Check filters and set PyTables format version for new files.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"id":"seeGM_y9nsLj","colab_type":"text"},"cell_type":"markdown","source":["run for the whole subset"]},{"metadata":{"id":"VL-iTZSNnuix","colab_type":"code","colab":{}},"cell_type":"code","source":["t1 = time.time()\n","apply_to_all_files(msd_subset_data_path,func=extractAudio)\n","t2 = time.time()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"bsCMMN9XmTFS","colab_type":"text"},"cell_type":"markdown","source":["Extracting the features"]},{"metadata":{"id":"Q2V2Gm8rlxzw","colab_type":"code","colab":{}},"cell_type":"code","source":["Audio = [\n","    all_analysis_sample_rate,\n","    all_time_signature,\n","    all_tempo,\n","    all_segments_pitches,\n","    all_segments_timbre, #pure mfcc\n","    all_segments_loudness_max\n","]\n","AudioLabels = [\n","    'analysis_sample_rate',\n","    'time_signature',\n","    'tempo',\n","    'segments_pitches',\n","    'segments_timbre', #pure mfcc\n","    'segments_loudness_max'\n","]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"eidfcN68mpQ-","colab_type":"code","colab":{}},"cell_type":"code","source":["dataAudio = pd.DataFrame(Audio,index = AudioLabels, columns = all_song_id)\n","audioData = dataAudio.transpose()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"eDDKzWNAmwCP","colab_type":"code","outputId":"d1512c02-49d9-4810-f95f-e457464a7633","executionInfo":{"status":"error","timestamp":1544288664301,"user_tz":-60,"elapsed":493,"user":{"displayName":"Sonja Füllhase","photoUrl":"","userId":"11794806925355905588"}},"colab":{"base_uri":"https://localhost:8080/","height":164}},"cell_type":"code","source":["audioData.head()"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-152-a5cee6dbbd77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maudioData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'audioData' is not defined"]}]},{"metadata":{"id":"IvTqI9cXC05z","colab_type":"text"},"cell_type":"markdown","source":["## Get training and test indices\n"]},{"metadata":{"id":"xQ005lp98i2z","colab_type":"code","colab":{}},"cell_type":"code","source":["def add_prevalent_tag(df):\n","    \"\"\"Adds the prevalent tag/artist_term/genre as a column\"\"\"\n","    # Adds a column with the highest weighted tag\n","    df['prevalent_tag'] = df['artist_terms'].apply(lambda tags: tags[0] if len(tags)>0 else b'other')\n","\n","    # Get array of all prevalent tags (all_tags)\n","    all_tags = df['prevalent_tag'].values\n","    i = 0\n","    for index, song in df.iterrows():\n","        # Delete prevalent term of that song from array\n","        all_tags[i] = None\n","        # Go through song_tags until you find a tag that already occurs for \n","        # another song or end of song_tags\n","        song_tags = song['artist_terms']\n","        single = True\n","        j = 0\n","        while single and j<len(song_tags):\n","            new_tag = song_tags[j]\n","            j += 1\n","            if new_tag in all_tags:\n","                single = False\n","        if single:\n","            new_tag = b'other'\n","        df.iloc[i]['prevalent_tag'] = new_tag \n","        all_tags[i] = new_tag\n","        i += 1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"j6fWK7j7Dru5","colab_type":"code","colab":{}},"cell_type":"code","source":["def get_train_test_split(df, test_size=0.2, stratify=True):\n","    \"\"\"Returns train and test split\"\"\"\n","    if stratify:\n","        split = train_test_split(df, test_size=test_size, shuffle=True, stratify=df['prevalent_tag'])\n","    else: \n","        split = train_test_split(df, test_size=test_size, shuffle=True)\n","    return split"],"execution_count":0,"outputs":[]},{"metadata":{"id":"lMw-kU4tJbbV","colab_type":"code","colab":{}},"cell_type":"code","source":["def save_train_test_split(data):\n","    \"\"\"Saves the IDs for training and testing data in a .npy file.\n","    Stratifies according to the prevalent tag/genre\"\"\"\n","    df = data.copy()\n","    add_prevalent_tag(df)\n","    train, test = get_train_test_split(df, stratify=False)\n","    train_indices = list(train.index)\n","    test_indices = list(test.index)\n","    np.save('/content/drive/My Drive/IR/Dataprocessing/TrainTestSplit/TrainIndices', train_indices)\n","    np.save('/content/drive/My Drive/IR/Dataprocessing/TrainTestSplit/TestIndices', test_indices)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3PjY-tykHdSv","colab_type":"code","colab":{}},"cell_type":"code","source":["save_train_test_split(nonAudioData)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"H6qE4_3WNU2R","colab_type":"code","colab":{}},"cell_type":"code","source":["train_ids = np.load('/content/drive/My Drive/IR/Dataprocessing/TrainTestSplit/TrainIndices.npy')\n","train_data = nonAudioData.loc[train_ids]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MsHOMX9LYPme","colab_type":"text"},"cell_type":"markdown","source":["## Get evaluation playlist\n","Use **get_all_tags(nonAudioData)** to get all possible tags \\\\\n","Use **get_playlist(nonAudioData, tag, max_length)** to get a playlist with desired length sorted by tag_weight for given tag"]},{"metadata":{"id":"JKCEfD_6e93K","colab_type":"code","colab":{}},"cell_type":"code","source":["def get_all_tags(df):\n","    \"\"\"Returns a list of all tags/artist_terms\"\"\"\n","    return list(set(np.concatenate(df['artist_terms'].values)))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QMWRj057i-_W","colab_type":"code","colab":{}},"cell_type":"code","source":["def get_songs_with_tag(df, tag):\n","    \"\"\"Returns a DataFrame containing all songs that were tagged with a given\n","    tag/artist_term.\"\"\"\n","    mask = []\n","    for tags in df['artist_terms'].values:\n","        if tag in tags:\n","            mask.append(True)\n","        else:\n","            mask.append(False)\n","    return df[mask]\n","\n","\n","#example use: get_songs_with_tag(nonAudioData, b'jazz')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Wwcbn8XX3_Vb","colab_type":"code","colab":{}},"cell_type":"code","source":["def get_tag_weight(song, tag):\n","    \"\"\"Returns the tag_weight/artist_term_weight for a given song and a given tag/artist_term\"\"\"\n","    tags = song['artist_terms']\n","    tag_weights = song['artist_terms_weight']\n","    return tag_weights[list(tags).index(tag)]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"bd0CK6W_pVyJ","colab_type":"code","colab":{}},"cell_type":"code","source":["def get_genre_playlist(df, tag, max_length=10):\n","    \"\"\"Returns a playlist with desired length sorted by tag_weight/artist_term_weight for a \n","    given tag/artist term\"\"\"\n","    # get all songs with the given tag\n","    playlist = get_songs_with_tag(df, tag)\n","    # create new column with weight of given tag\n","    playlist = playlist.assign(weight=playlist.apply(lambda x: get_tag_weight(x, tag), axis=1))\n","    # sort by tag weight\n","    playlist = playlist.sort_values(by=\"weight\", ascending=False)\n","    # clip after max_length songs\n","    playlist = playlist.iloc[:max_length]\n","    return playlist"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4DwI5IQKW77t","colab_type":"code","colab":{}},"cell_type":"code","source":["def get_playlist(df, length=100):\n","    \"\"\"Returns a playlist with desired length with songs from several random genres\"\"\"\n","    playlist = pd.DataFrame()\n","    all_tags = get_all_tags(df)\n","    nb_tags = len(all_tags)\n","    while len(playlist)<length:\n","        # Get a random tag and remove it from all_tags (so it won't be reused)\n","        random_tag = random.choice(all_tags)\n","        print(random_tag)\n","        all_tags.remove(random_tag)        \n","        # Get playlist for the random tag\n","        max_length = length - len(playlist)\n","        genre_playlist = get_genre_playlist(df, random_tag, max_length=max_length)\n","        \n","        # Add genre playlist to playlist\n","        playlist = playlist.append(genre_playlist)\n","    return playlist\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CuM_OejED4gf","colab_type":"code","outputId":"0539c5fe-a02b-4671-e33b-b1db6842ff1c","executionInfo":{"status":"ok","timestamp":1544353681258,"user_tz":-60,"elapsed":670,"user":{"displayName":"Sonja Füllhase","photoUrl":"","userId":"11794806925355905588"}},"colab":{"base_uri":"https://localhost:8080/","height":751}},"cell_type":"code","source":["# Example use of get_playlist:\n","test_ids = np.load('/content/drive/My Drive/IR/Dataprocessing/TrainTestSplit/TestIndices.npy')\n","test_data = nonAudioData.loc[test_ids]\n","playlist = get_playlist(test_data, length=100)\n","playlist.head()"],"execution_count":40,"outputs":[{"output_type":"stream","text":["b'catalan'\n","b'colombian'\n","b'celtic folk metal'\n","b'crossover'\n","b'revolution hall'\n","b'latin funk'\n","b'female jazz singer'\n","b'jazz sax'\n","b'21st century'\n","b'new traditionalist'\n","b'west coast jazz'\n","b'patchanka'\n","b'dhr'\n","b'symphonic metal'\n","(100, 12)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>artist_id</th>\n","      <th>artist_name</th>\n","      <th>release</th>\n","      <th>title</th>\n","      <th>danceability</th>\n","      <th>track_id</th>\n","      <th>year</th>\n","      <th>similar_artists</th>\n","      <th>artist_terms</th>\n","      <th>artist_terms_freq</th>\n","      <th>artist_terms_weight</th>\n","      <th>weight</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>b'SOMXSEH12A8C1371EA'</th>\n","      <td>b'AR0693R1187FB59D32'</td>\n","      <td>b'Dusminguet'</td>\n","      <td>b'Postrof'</td>\n","      <td>b'San Cristobal'</td>\n","      <td>0</td>\n","      <td>b'TRABTSM128F426AF07'</td>\n","      <td>2001</td>\n","      <td>[b'ARG17O11187FB4A8DA', b'AR6QILA1187B98A966',...</td>\n","      <td>[b'rumba', b'cumbia', b'ska', b'reggae', b'fol...</td>\n","      <td>[0.973563040037711, 0.9363022377297834, 1.0, 0...</td>\n","      <td>[1.0, 0.9733234385539222, 0.9012296707565989, ...</td>\n","      <td>0.667301</td>\n","    </tr>\n","    <tr>\n","      <th>b'SOKTWWO12AB01841C2'</th>\n","      <td>b'AR61JEC1187FB54A9F'</td>\n","      <td>b'Ai Ai Ai'</td>\n","      <td>b'Neguits_ Angunies I Forats'</td>\n","      <td>b'Com Una Flama'</td>\n","      <td>0</td>\n","      <td>b'TRBGHKE128F9343BDD'</td>\n","      <td>1994</td>\n","      <td>[b'ARLTMAG11F50C4E4FB', b'ARG17O11187FB4A8DA',...</td>\n","      <td>[b'rumba', b'catalan', b'harp', b'catalonia', ...</td>\n","      <td>[1.0, 0.5264247776293095, 0.475945616151258, 0...</td>\n","      <td>[1.0, 0.6652856725794455, 0.6296079221720261, ...</td>\n","      <td>0.665286</td>\n","    </tr>\n","    <tr>\n","      <th>b'SOSFWSU12A8AE46BB9'</th>\n","      <td>b'ARQDYV0119B866800F'</td>\n","      <td>b'Gertrudis'</td>\n","      <td>b'Teta'</td>\n","      <td>b'Carita De Rosa'</td>\n","      <td>0</td>\n","      <td>b'TRBFVDB128F423EA48'</td>\n","      <td>2003</td>\n","      <td>[b'ARG17O11187FB4A8DA', b'ARRXHMJ11F50C4E4FA',...</td>\n","      <td>[b'big beat', b'dub', b'rumba', b'new wave', b...</td>\n","      <td>[0.9565680157818903, 1.0, 0.8253407709908128, ...</td>\n","      <td>[1.0, 0.9453905820360166, 0.8977955559627417, ...</td>\n","      <td>0.616609</td>\n","    </tr>\n","    <tr>\n","      <th>b'SOYXJBB12AB017D968'</th>\n","      <td>b'ARQDYV0119B866800F'</td>\n","      <td>b'Gertrudis'</td>\n","      <td>b'500'</td>\n","      <td>b'Oye'</td>\n","      <td>0</td>\n","      <td>b'TRATUUD128F9307F90'</td>\n","      <td>2005</td>\n","      <td>[b'ARG17O11187FB4A8DA', b'ARRXHMJ11F50C4E4FA',...</td>\n","      <td>[b'big beat', b'dub', b'rumba', b'new wave', b...</td>\n","      <td>[0.9565680157818903, 1.0, 0.8253407709908128, ...</td>\n","      <td>[1.0, 0.9453905820360166, 0.8977955559627417, ...</td>\n","      <td>0.616609</td>\n","    </tr>\n","    <tr>\n","      <th>b'SOYIZXR12A8AE4633F'</th>\n","      <td>b'ARQDYV0119B866800F'</td>\n","      <td>b'Gertrudis'</td>\n","      <td>b'Teta'</td>\n","      <td>b'Quitxalla'</td>\n","      <td>0</td>\n","      <td>b'TRAVBMS128F423EA54'</td>\n","      <td>2003</td>\n","      <td>[b'ARG17O11187FB4A8DA', b'ARRXHMJ11F50C4E4FA',...</td>\n","      <td>[b'big beat', b'dub', b'rumba', b'new wave', b...</td>\n","      <td>[0.9565680157818903, 1.0, 0.8253407709908128, ...</td>\n","      <td>[1.0, 0.9453905820360166, 0.8977955559627417, ...</td>\n","      <td>0.616609</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                   artist_id    artist_name  \\\n","b'SOMXSEH12A8C1371EA'  b'AR0693R1187FB59D32'  b'Dusminguet'   \n","b'SOKTWWO12AB01841C2'  b'AR61JEC1187FB54A9F'    b'Ai Ai Ai'   \n","b'SOSFWSU12A8AE46BB9'  b'ARQDYV0119B866800F'   b'Gertrudis'   \n","b'SOYXJBB12AB017D968'  b'ARQDYV0119B866800F'   b'Gertrudis'   \n","b'SOYIZXR12A8AE4633F'  b'ARQDYV0119B866800F'   b'Gertrudis'   \n","\n","                                             release              title  \\\n","b'SOMXSEH12A8C1371EA'                     b'Postrof'   b'San Cristobal'   \n","b'SOKTWWO12AB01841C2'  b'Neguits_ Angunies I Forats'   b'Com Una Flama'   \n","b'SOSFWSU12A8AE46BB9'                        b'Teta'  b'Carita De Rosa'   \n","b'SOYXJBB12AB017D968'                         b'500'             b'Oye'   \n","b'SOYIZXR12A8AE4633F'                        b'Teta'       b'Quitxalla'   \n","\n","                      danceability               track_id  year  \\\n","b'SOMXSEH12A8C1371EA'            0  b'TRABTSM128F426AF07'  2001   \n","b'SOKTWWO12AB01841C2'            0  b'TRBGHKE128F9343BDD'  1994   \n","b'SOSFWSU12A8AE46BB9'            0  b'TRBFVDB128F423EA48'  2003   \n","b'SOYXJBB12AB017D968'            0  b'TRATUUD128F9307F90'  2005   \n","b'SOYIZXR12A8AE4633F'            0  b'TRAVBMS128F423EA54'  2003   \n","\n","                                                         similar_artists  \\\n","b'SOMXSEH12A8C1371EA'  [b'ARG17O11187FB4A8DA', b'AR6QILA1187B98A966',...   \n","b'SOKTWWO12AB01841C2'  [b'ARLTMAG11F50C4E4FB', b'ARG17O11187FB4A8DA',...   \n","b'SOSFWSU12A8AE46BB9'  [b'ARG17O11187FB4A8DA', b'ARRXHMJ11F50C4E4FA',...   \n","b'SOYXJBB12AB017D968'  [b'ARG17O11187FB4A8DA', b'ARRXHMJ11F50C4E4FA',...   \n","b'SOYIZXR12A8AE4633F'  [b'ARG17O11187FB4A8DA', b'ARRXHMJ11F50C4E4FA',...   \n","\n","                                                            artist_terms  \\\n","b'SOMXSEH12A8C1371EA'  [b'rumba', b'cumbia', b'ska', b'reggae', b'fol...   \n","b'SOKTWWO12AB01841C2'  [b'rumba', b'catalan', b'harp', b'catalonia', ...   \n","b'SOSFWSU12A8AE46BB9'  [b'big beat', b'dub', b'rumba', b'new wave', b...   \n","b'SOYXJBB12AB017D968'  [b'big beat', b'dub', b'rumba', b'new wave', b...   \n","b'SOYIZXR12A8AE4633F'  [b'big beat', b'dub', b'rumba', b'new wave', b...   \n","\n","                                                       artist_terms_freq  \\\n","b'SOMXSEH12A8C1371EA'  [0.973563040037711, 0.9363022377297834, 1.0, 0...   \n","b'SOKTWWO12AB01841C2'  [1.0, 0.5264247776293095, 0.475945616151258, 0...   \n","b'SOSFWSU12A8AE46BB9'  [0.9565680157818903, 1.0, 0.8253407709908128, ...   \n","b'SOYXJBB12AB017D968'  [0.9565680157818903, 1.0, 0.8253407709908128, ...   \n","b'SOYIZXR12A8AE4633F'  [0.9565680157818903, 1.0, 0.8253407709908128, ...   \n","\n","                                                     artist_terms_weight  \\\n","b'SOMXSEH12A8C1371EA'  [1.0, 0.9733234385539222, 0.9012296707565989, ...   \n","b'SOKTWWO12AB01841C2'  [1.0, 0.6652856725794455, 0.6296079221720261, ...   \n","b'SOSFWSU12A8AE46BB9'  [1.0, 0.9453905820360166, 0.8977955559627417, ...   \n","b'SOYXJBB12AB017D968'  [1.0, 0.9453905820360166, 0.8977955559627417, ...   \n","b'SOYIZXR12A8AE4633F'  [1.0, 0.9453905820360166, 0.8977955559627417, ...   \n","\n","                         weight  \n","b'SOMXSEH12A8C1371EA'  0.667301  \n","b'SOKTWWO12AB01841C2'  0.665286  \n","b'SOSFWSU12A8AE46BB9'  0.616609  \n","b'SOYXJBB12AB017D968'  0.616609  \n","b'SOYIZXR12A8AE4633F'  0.616609  "]},"metadata":{"tags":[]},"execution_count":40}]},{"metadata":{"id":"aw1CV_7rmSkA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1252},"outputId":"fa8416cc-94be-4937-d36a-dbdd904b86c6","executionInfo":{"status":"error","timestamp":1544353623330,"user_tz":-60,"elapsed":396,"user":{"displayName":"Sonja Füllhase","photoUrl":"","userId":"11794806925355905588"}}},"cell_type":"code","source":["playlist['most_common_rating'].value_counts().plot(x='Most common rating',\n","                                                   y='# occurences', \n","                                                   kind=\"bar\", \n","                                                   rot=25)"],"execution_count":37,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2524\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2525\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2526\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'most_common_rating'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-37-e8c808ea77f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m playlist['most_common_rating'].value_counts().plot(x='Most common rating',\n\u001b[0m\u001b[1;32m      2\u001b[0m                                                    \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'# occurences'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                                    \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"bar\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                    rot=25)\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2137\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2138\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2144\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2146\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1840\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1842\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1843\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1844\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3842\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3843\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3844\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3845\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2525\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2526\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2527\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2529\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'most_common_rating'"]}]},{"metadata":{"id":"6K3toolFpisz","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}